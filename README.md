# VaultFlex

**Chat with your Knowledge** using a hybrid RAG pipeline (Vector + Graph). Built for teams that want full control over their data.

## ğŸš€ Features

- ğŸ“ **Flexible Knowledge Base Scopes** â€” create isolated workspaces per domain or project
- ğŸ§  **Hybrid Retrieval** â€” combines vector search (FAISS) and knowledge graphs (Neo4j)
- ğŸ” **LLM-Augmented Reasoning** â€” responds only from your ingested content (no hallucinations)
- ğŸ§¾ **Document Parsing** â€” PDF, DOCX, Markdown, TXT support
- ğŸª„ **Interactive UI** â€” powered by Streamlit, clean and customisable
- ğŸ’¾ **Medallion Architecture** â€” Bronze â†’ Silver â†’ Gold data layers

## ğŸ“ Medallion Architecture

VaultFlex follows a structured **Medallion data pipeline**:

- ğŸ¥‰ **Bronze**: Raw document storage
- ğŸ¥ˆ **Silver**: Cleaned and chunked JSON text
- ğŸ¥‡ **Gold**: Embeddings stored in FAISS for semantic search + graphs in Neo4j

Each knowledge base scope maintains its own isolated Bronze/Silver/Gold structure. This enables reproducible, debuggable, and extendable pipelines.

```
VaultFlex/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ <dataset_name>/
â”‚       â”œâ”€â”€ bronze/       # Raw documents (PDF, DOCX, etc.)
â”‚       â”œâ”€â”€ silver/       # Chunked and cleaned JSON text
â”‚       â””â”€â”€ gold/         # FAISS vector store
```

## ğŸ” Hybrid Pipeline Workflow

```
          User Upload
               â”‚
           [Bronze]
               â”‚
     Chunking + Cleaning
               â†“
           [Silver]
               â”‚
   Embedding + FAISS Indexing
               â†“
           [Gold]
               â”‚
     + Graph Triples (Neo4j)
```

## ğŸ§ª Technologies

- `Streamlit` â€” UI
- `FAISS` + `HuggingFace` â€” Embedding & vector storage
- `Neo4j` â€” Knowledge graph backend
- `LangChain` â€” Document parsing and chunking
- `Ollama` / `LLM API` â€” Model communication

---

## ğŸ“¦ Project Structure

```
VaultFlex/
â”œâ”€â”€ data/                    # All datasets (Bronze/Silver/Gold)
â”‚   â”œâ”€â”€ bronze/             # Raw uploaded documents per KB
â”‚   â”œâ”€â”€ silver/             # Chunked documents as JSON
â”‚   â”œâ”€â”€ gold/               # FAISS vector indexes
â”‚   â””â”€â”€ ingested_hashes.json
â”œâ”€â”€ doc/                    # Docs and branding
â”‚   â””â”€â”€ images/vaultFlex_logo.png
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ui/                 # Streamlit UI modules
â”‚   â”œâ”€â”€ vector/             # Embedding, graph builder, retriever
â”‚   â”œâ”€â”€ utils/              # Utility tools (e.g. service checks)
â”‚   â”œâ”€â”€ config.py           # Centralised paths and settings
â”‚   â””â”€â”€ __version__.py
â”œâ”€â”€ main.py                 # App entry point
â”œâ”€â”€ environment.yml         # Conda environment setup
â”œâ”€â”€ requirements.txt        # Pip requirements
â””â”€â”€ README.md               # You're reading it

```

---

## ğŸ§  LLM Usage

VaultFlex calls your selected local/remote LLM to:
- Refine vague user questions
- Synthesise answers from graph triples and chunks
- Avoid hallucination by grounding output in source data

Supports: `deepseek-r1`, `gemma3`, or anything via `Ollama`.

---

## ğŸ Quickstart

```bash
# 1. Start backend (Ollama and neo4j)
# 2. Install dependencies
pip install -r requirements.txt

# 3. Update .env
update .env

# 4. Launch the UI
streamlit run app.py
```

---

## ğŸ’¬ Example Use

- Upload multiple PDFs and DOCXs into `Finance` knowledge base
- Ask: *"what were the key themes discussed in quarterly reports?"*
- VaultFlex retrieves vector data, queries the graph, and answers using both


---

ğŸ¤ Made with â¤ï¸ by Anish Khadka - VaultFlex
