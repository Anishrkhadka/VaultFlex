# VaultFlex 
**Chat with your Knowledge** using a hybrid RAG pipeline (Vector + Graph). Built for teams that want full control over their data.

## ğŸš€ Features

- ğŸ“ **Flexible Knowledge Base Scopes** â€” create isolated workspaces per domain or project
- ğŸ§  **Hybrid Retrieval** â€” combines vector search (FAISS) and knowledge graphs (Neo4j)
- ğŸ” **LLM-Augmented Reasoning** â€” responds only from your ingested content (no hallucinations)
- ğŸ§¾ **Document Parsing** â€” PDF, DOCX, Markdown, TXT support
- ğŸª„ **Interactive UI** â€” powered by Streamlit, clean and customisable
- ğŸ’¾ **Medallion Data Architecture** â€” Bronze â†’ Silver â†’ Gold data layers

### ğŸ“ Medallion Data Architecture

VaultFlex follows a structured Medallion data pipeline to process documents:

* ğŸ¥‰ **Bronze**: Raw files uploaded by the user are stored.
* ğŸ¥ˆ **Silver**: Cleaned, chunked, and standardised text representations (JSON).
* ğŸ¥‡ **Gold**: Semantic embeddings stored in FAISS, and knowledge graphs built in Neo4j.

```
VaultFlex/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ <dataset_name>/
â”‚       â”œâ”€â”€ bronze/       # Raw documents (PDF, DOCX, etc.)
â”‚       â”œâ”€â”€ silver/       # Chunked and cleaned JSON text
â”‚       â””â”€â”€ gold/         # FAISS vector store (and in Neo4j)
```

---

### ğŸ›¡ï¸ Smart Upload: Hash-Based Deduplication

VaultFlex automatically prevents duplicate document ingestion:

* âœ… On upload, each file is hashed (e.g., SHA256).
* ğŸš« If the same file (even renamed) was previously uploaded, it's rejected.
* ğŸ’¾ This ensures clean, efficient, and consistent data processing.

Hashes are tracked in a persistent file: `HASH_TRACK_FILE`, with scope-aware keys like `finance/employee_policy.pdf`.


## ğŸ§ª Technologies

- `Streamlit` â€” UI
- `FAISS` + `HuggingFace` â€” Embedding & vector storage
- `Neo4j` â€” Knowledge graph backend
- `LangChain` â€” Document parsing and chunking
- `Ollama` / `LLM API` â€” Model communication

---

## ğŸ“¦ Project Structure

```
VaultFlex/
â”œâ”€â”€ data/                    # All datasets (Bronze/Silver/Gold)
â”‚   â”œâ”€â”€ bronze/             # Raw uploaded documents per KB
â”‚   â”œâ”€â”€ silver/             # Chunked documents as JSON
â”‚   â”œâ”€â”€ gold/               # FAISS vector indexes
â”‚   â””â”€â”€ ingested_hashes.json
â”œâ”€â”€ doc/                    # Docs and branding
â”‚   â””â”€â”€ images/vaultFlex_logo.png
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ui/                 # Streamlit UI modules
â”‚   â”œâ”€â”€ vector/             # Embedding, graph builder, retriever
â”‚   â”œâ”€â”€ utils/              # Utility tools (e.g. service checks)
â”‚   â”œâ”€â”€ config.py           # Centralised paths and settings
â”‚   â””â”€â”€ __version__.py
â”œâ”€â”€ main.py                 # App entry point
â”œâ”€â”€ environment.yml         # Conda environment setup
â”œâ”€â”€ requirements.txt        # Pip requirements
â””â”€â”€ README.md               # You're reading it

```
### ğŸ” Pipeline Workflow

```mermaid
flowchart TD
    %% UI Layer
    subgraph UI ["ğŸ–¥ï¸ Streamlit UI"]
        A["ğŸ“„ Upload Docs"] --> B["ğŸ§­ Choose Dataset Scope"]
        B --> C["ğŸ“Œ Select LLM"]
        C --> D["ğŸ’¬ Ask Question"]
    end

    %% Bronze Layer
    subgraph Bronze ["ğŸ¥‰ Bronze Layer â€“ Raw Documents"]
        B --> E["ğŸ§¹ Preprocess + Dedup"]
        E --> F["ğŸ’¾ Store Raw Files"]
    end

    %% Silver Layer
    subgraph Silver ["ğŸ¥ˆ Silver Layer â€“ Cleaned Chunks"]
        F --> G["ğŸ§© Text Chunking"]
        G --> H["ğŸ“„ Store Cleaned Chunks (JSON)"]
    end

    %% Gold Layer
    subgraph Gold ["ğŸ¥‡ Gold Layer â€“ Indexes & Knowledge"]
        G --> I["ğŸ” Generate Embeddings (FAISS)"]
        G --> J["ğŸ§  Extract Triples (Entities & Relations)"]
        I --> K["ğŸ“š FAISS Index"]
        J --> L["ğŸ•¸ï¸ Neo4j Graph DB"]
    end

    %% Query Flow
    D --> Q["ğŸ§  Enhance Query via LLM"]
    Q --> M1["ğŸ” Retrieve Context from FAISS"]
    Q --> M2["ğŸŒ Query Neo4j (GraphRAG)"]
    M1 --> N["ğŸ§  LLM Generates Final Answer"]
    M2 --> N

    %% Styling
    classDef bronze fill:#e8f5e9,stroke:#2e7d32,stroke-width:2px
    classDef silver fill:#e3f2fd,stroke:#1565c0,stroke-width:2px
    classDef gold fill:#fff8e1,stroke:#f9a825,stroke-width:2px
    classDef ui fill:#f3e5f5,stroke:#6a1b9a,stroke-width:2px
    classDef query fill:#ede7f6,stroke:#512da8,stroke-width:2px
    classDef enhance fill:#fce4ec,stroke:#ad1457,stroke-width:2px

    class UI ui
    class Bronze bronze
    class Silver silver
    class Gold gold
    class Q enhance
    class M1,M2,N query


```

---

## ğŸ§  LLM Usage

VaultFlex calls your selected local LLM to:
- Refine vague user questions
- Synthesise answers from graph triples and chunks
- Avoid hallucination by grounding output in source data

Supports: `deepseek-r1`, `gemma3`, or anything via `Ollama`.

---

## ğŸ Quickstart

```bash
# 1. Start backend (Ollama and neo4j)
# 2. Install dependencies
pip install -r requirements.txt

# 3. Update .env (see env_template)
update .env

# 4. Launch the UI
streamlit run app.py
```

---

## ğŸ’¬ Example Use

- Upload multiple PDFs and DOCXs into `Finance` knowledge base
- Ask: *"what were the key themes discussed in quarterly reports?"*
- VaultFlex retrieves vector data, queries the graph, and answers using both


---

ğŸ¤ Made with â¤ï¸ by Anish Khadka - VaultFlex
